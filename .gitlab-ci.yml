include:
  - local: 'gitlab-ci/main.yml'

# Pipeline overrides and customizations can be added here
# These will override any shared configuration from main.yml

variables:
  # Add or override variables from main.yml
  PYTHON_VERSION: "3.10"
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  # Environment-specific deployment variables
  DEV_SERVER_HOST: "dev-dagster.example.com"
  DEV_SERVER_USER: "dagster"
  DEV_DEPLOY_PATH: "/opt/dagster/deploy"
  STAGING_SERVER_HOST: "staging-dagster.example.com"
  STAGING_SERVER_USER: "dagster"
  STAGING_DEPLOY_PATH: "/opt/dagster/deploy"
  PROD_SERVER_HOST: "prod-dagster.example.com"
  PROD_SERVER_USER: "dagster"
  PROD_DEPLOY_PATH: "/opt/dagster/deploy"
  # GitHub Container Registry variables
  GHCR_REGISTRY: "ghcr.io"
  GHCR_IMAGE: "ghcr.io/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME"

cache:
  paths:
    - .pip-cache/
    - .uv/
    - .ruff_cache/

# Shared configuration for Python jobs
.python_template:
  image: python:${PYTHON_VERSION}-slim
  before_script:
    # Install uv via curl to avoid using pip install
    - curl -Ls https://astral.sh/uv/install.sh | bash
    - export PATH="$HOME/.cargo/bin:$PATH"
    - uv venv
    - uv sync

lint:
  stage: lint
  extends: .python_template
  script:
    # Use uv sync to install dependencies instead of pip install
    - uv sync --group dev
    - uv run ruff check .
    - uv run mypy src/clustering

test:
  stage: test
  extends: .python_template
  script:
    # Use uv sync to install test dependencies
    - uv sync --group test
    - uv run pytest tests/ -v --cov=src/clustering
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

build:
  stage: build
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  script:
    # Build, tag and push to GitLab Container Registry
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG .
    - |
      if [ "$CI_COMMIT_BRANCH" == "main" ]; then
        docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG $CI_REGISTRY_IMAGE:latest
      fi
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
    - |
      if [ "$CI_COMMIT_BRANCH" == "main" ]; then
        docker push $CI_REGISTRY_IMAGE:latest
      fi
    
    # Build, tag and push to GitHub Container Registry
    - docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG $GHCR_IMAGE:$CI_COMMIT_REF_SLUG
    - |
      if [ "$CI_COMMIT_BRANCH" == "main" ]; then
        docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG $GHCR_IMAGE:latest
      fi
    - echo $GITHUB_TOKEN | docker login $GHCR_REGISTRY -u $GITHUB_USER --password-stdin
    - docker push $GHCR_IMAGE:$CI_COMMIT_REF_SLUG
    - |
      if [ "$CI_COMMIT_BRANCH" == "main" ]; then
        docker push $GHCR_IMAGE:latest
      fi
    
    # Tag with version number if this is a tagged release
    - |
      if [[ "$CI_COMMIT_TAG" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
        VERSION=${CI_COMMIT_TAG#v}
        docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG $CI_REGISTRY_IMAGE:$VERSION
        docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG $GHCR_IMAGE:$VERSION
        docker push $CI_REGISTRY_IMAGE:$VERSION
        docker push $GHCR_IMAGE:$VERSION
      fi

# You can add or override specific jobs here
validate_pipeline:
  before_script:
    # Install uv via curl to avoid using pip install
    - curl -Ls https://astral.sh/uv/install.sh | bash
    - export PATH="$HOME/.cargo/bin:$PATH"
    - uv venv
    - uv sync
    - mkdir -p ${CI_PROJECT_DIR}/dagster_home
    - export DAGSTER_HOME=${CI_PROJECT_DIR}/dagster_home

# Specific configuration for production deployment
deploy_prod:
  # Additional configuration for production deployment
  # This will be merged with the one from main.yml
  when: manual
  script:
    - uv sync
    - mkdir -p ~/.ssh
    - echo "$PROD_SSH_PRIVATE_KEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - ssh-keyscan -H $PROD_SERVER_HOST >> ~/.ssh/known_hosts
    - |
      ssh $PROD_SERVER_USER@$PROD_SERVER_HOST << EOF
        cd $PROD_DEPLOY_PATH
        
        # Stop existing services
        docker-compose down
        
        # Pull new images
        docker-compose pull
        
        # Create required directories
        mkdir -p data/internal data/external data/merging
        
        # Set environment variables
        cat > .env << ENVEOF
        DAGSTER_HOME=/opt/dagster/dagster_home
        DATA_DIR=/opt/dagster/data
        INTERNAL_DATA_DIR=/opt/dagster/data/internal
        EXTERNAL_DATA_DIR=/opt/dagster/data/external
        MERGING_DATA_DIR=/opt/dagster/data/merging
        ENVIRONMENT=prod
        DOCKER_REGISTRY=${GHCR_REGISTRY}
        TAG=${CI_COMMIT_TAG#v}
        ENVEOF
        
        # Start services
        docker-compose up -d
        
        # Verify deployment
        docker-compose ps
        echo "Deployment to PRODUCTION complete"
      EOF
  rules:
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/'
      when: manual
    - if: '$CI_COMMIT_BRANCH == "main" && $FORCE_PROD_DEPLOY == "true"'
      when: manual
