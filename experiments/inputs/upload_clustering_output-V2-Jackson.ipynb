{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16a1388-4a02-4732-bfc0-2dbcb147e6ee",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7187689e-4b71-41e8-89da-0d3a5065872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside config.py slfsvc-twa07\n",
      "printing snowflake connection dic {'tenant': 'fabb61b8-3afe-4e75-b934-a47f782b8cd7', 'client_id': '5617df5a-e4aa-4898-8260-9ac51b67e1c0', 'akssecret': 'prod-fspe-sp-secret', 'vault': 'kv-rtlfspekv0701slfsvc07', 'sfsecretkey': 'sfkey', 'sfkeypass': 'sfpasskey'}\n",
      "Initiating azcopy login\n",
      "az login succeeded\n"
     ]
    }
   ],
   "source": [
    "# %pip install fsutils --user\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import itertools as it\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.spatial import distance\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from fsutils import run_sf_sql as rp, config, email, adls_gen2, log\n",
    "\n",
    "# from utils.utils import worker_output_table_validation\n",
    "from multiprocessing import Pool, freeze_support\n",
    "from snowflake.connector.connection import SnowflakeConnection, SnowflakeCursor\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# from pandasql import sqldf\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "# Pandas Display Settings\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.width\", None)  # Set width to None to avoid wrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f6411-8b4f-4b6e-b827-d41ce9668315",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9965c9b-4cbb-4cdb-a4c0-8f08322ceae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_datetime_token(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the date/time token at the end of filenames like:\n",
    "    merged_clusters_PERSONAL_CLEANSING_20250212_1301.csv\n",
    "    Returning '20250212_1301'.\n",
    "    \"\"\"\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        return None  # skip anything that isn't a CSV\n",
    "    no_ext = filename.split(\".\")[0]  # e.g., merged_clusters_PERSONAL_CLEANSING_20250212_1301\n",
    "    tokens = no_ext.split(\"_\")\n",
    "    if len(tokens) < 3:\n",
    "        return None  # skip anything that doesn't have at least two underscores\n",
    "    return tokens[-2] + \"_\" + tokens[-1]  # e.g. 20250212_1301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772d1cd4-e410-4467-bd1f-e3799f544dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_datetime_token(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the date/time token at the end of filenames like:\n",
    "    merged_clusters_PERSONAL_CLEANSING_20250212_1301.csv\n",
    "    Returning '20250212_1301'.\n",
    "    \"\"\"\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        return None  # skip anything that isn't a CSV\n",
    "    no_ext = filename.split(\".\")[0]\n",
    "    tokens = no_ext.split(\"_\")\n",
    "    if len(tokens) < 3:\n",
    "        return None\n",
    "    return tokens[-2] + \"_\" + tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5b4ab3-438c-4b1d-a19c-5506ca7c816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_str(s: str) -> str:\n",
    "    \"\"\"\n",
    "    A helper to normalize the strings for matching.\n",
    "    Example: 'HAND_&_BODY' -> 'HAND & BODY', 'ORAL_HYGIENE' -> 'ORAL HYGIENE', etc.\n",
    "    Adjust as needed for your use-case.\n",
    "    \"\"\"\n",
    "    # Replace `_&_` with ` & `\n",
    "    s = s.replace(\"_&_\", \" & \")\n",
    "    # Replace all remaining underscores with spaces\n",
    "    s = s.replace(\"_\", \" \")\n",
    "    # Strip and make uppercase (or whichever case you prefer)\n",
    "    s = s.strip().upper()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489f4623-a950-4474-9873-50d627afc930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match(query: str, valid_list: list) -> str:\n",
    "    \"\"\"\n",
    "    Use difflib to get the closest match from valid_list to the query string.\n",
    "    Returns None if there is no close match at all, else returns the best guess.\n",
    "    \"\"\"\n",
    "    # difflib.get_close_matches(query, possibilities, n=1, cutoff=0.0)\n",
    "    # will return a list of the single best match, or empty if none.\n",
    "    matches = difflib.get_close_matches(query, valid_list, n=1, cutoff=0.0)\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2061e28e-d1a5-4349-af4f-2eb386ae506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, create a new column in df_filtered called \"CAT_DSC\"\n",
    "def map_category_to_cat_dsc(category_value: str) -> str:\n",
    "    # Step 1: Normalize the category_value\n",
    "    norm_cat = normalize_str(category_value)\n",
    "    # Step 2: Find the closest normalized official\n",
    "    best_normed = get_closest_match(norm_cat, normalized_official)\n",
    "    if best_normed is not None:\n",
    "        # Return the original official category text\n",
    "        return normalized_to_original[best_normed]\n",
    "    else:\n",
    "        # Fallback if no match at all\n",
    "        return category_value  # or some sentinel like \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b8440a-570e-417a-8543-582875bd18a5",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e1d64a-ae4f-4e59-b0e4-296143c336fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/home/jovyan/older code/notebooks/clustering_output/\"\n",
    "\n",
    "\n",
    "def get_last_datetime_token(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the date/time token at the end of filenames like:\n",
    "    merged_clusters_PERSONAL_CLEANSING_20250212_1301.csv\n",
    "    Returning '20250212_1301'.\n",
    "    \"\"\"\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        return None  # skip anything that isn't a CSV\n",
    "    no_ext = filename.split(\".\")[0]  # e.g., merged_clusters_PERSONAL_CLEANSING_20250212_1301\n",
    "    tokens = no_ext.split(\"_\")\n",
    "    if len(tokens) < 3:\n",
    "        return None  # skip anything that doesn't have at least two underscores\n",
    "    return tokens[-2] + \"_\" + tokens[-1]  # e.g. 20250212_1301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "059d6ee9-27da-4ae9-9d85-faa2b99473cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(directory_path)\n",
    "# Filter down to only valid date/time tokens\n",
    "valid_times = []\n",
    "for f in all_files:\n",
    "    dt = get_last_datetime_token(f)\n",
    "    if dt is not None:\n",
    "        valid_times.append(dt)\n",
    "if not valid_times:\n",
    "    raise ValueError(\"No valid CSV files found in directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7e6406-7253-4b9b-992e-db11ff083f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earliest_datetime = 20250414_1639\n"
     ]
    }
   ],
   "source": [
    "# Find the earliest (smallest) date/time across all files\n",
    "earliest_datetime = min(valid_times)\n",
    "print(\"earliest_datetime =\", earliest_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2827507-b384-427b-9cc6-ad113efcc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite all files to have the same end path as the earliest date/time\n",
    "for file in all_files:\n",
    "    dt = get_last_datetime_token(file)\n",
    "    if dt is not None:\n",
    "        new_filename = file.replace(dt, earliest_datetime)\n",
    "        os.rename(os.path.join(directory_path, file), os.path.join(directory_path, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f513307-0ada-4a2a-b078-e9a5397228ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now only read files that contain that earliest date/time\n",
    "dfs = []\n",
    "for file in os.listdir(directory_path):\n",
    "    dt = get_last_datetime_token(file)\n",
    "    if dt == earliest_datetime:\n",
    "        df = pd.read_csv(os.path.join(directory_path, file))\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes\n",
    "dfs = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a6598fd-0d5f-4e86-9f16-a45f6b9d5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates : False\n",
      "1:1 mismatch : False\n"
     ]
    }
   ],
   "source": [
    "# Add a category column\n",
    "dfs[\"category\"] = dfs[\"external_granularity\"].str.split(\"_\").str[:-2].str.join(\"_\")\n",
    "\n",
    "print(\"Duplicates :\", dfs[\"store_nbr\"].nunique() * dfs[\"category\"].nunique() < dfs.shape[0])\n",
    "print(\n",
    "    \"1:1 mismatch :\",\n",
    "    dfs[\"store_nbr\"].nunique() * dfs[\"category\"].nunique()\n",
    "    > dfs.drop_duplicates(subset=[\"store_nbr\", \"category\"]).shape[0],\n",
    ")\n",
    "\n",
    "df_filtered = dfs[\n",
    "    [\n",
    "        \"store_nbr\",\n",
    "        \"category\",\n",
    "        \"external_cluster_labels\",\n",
    "        \"internal_cluster_labels\",\n",
    "        \"demand_cluster_labels\",\n",
    "        \"rebalanced_demand_cluster_labels\",\n",
    "    ]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac1c491-81a4-4e0c-ac2e-299406847790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CANDY'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13173a25-1f78-40b8-9005-01002df49c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_nbr                           6827\n",
       "category                               1\n",
       "external_cluster_labels                8\n",
       "internal_cluster_labels                3\n",
       "demand_cluster_labels                 24\n",
       "rebalanced_demand_cluster_labels      15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4673df73-fbb2-4c1e-8d32-c8ccd93298aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 2) Manually define a dictionary that maps your existing category values\n",
    "# to the new CAT_DSC strings you'd like.\n",
    "# ----------------------------------------------------------------------------\n",
    "category_mapping = {\n",
    "    # Wave 1\n",
    "    \"VITAMINS\": \"VITAMINS\",\n",
    "    \"ORAL_HYGIENE\": \"ORAL HYGIENE\",\n",
    "    \"BEVERAGES\": \"BEVERAGES\",\n",
    "    \"PERSONAL_CLEANSING\": \"PERSONAL CLEANSING\",\n",
    "    \"HOUSEHOLD\": \"HOUSEHOLD\",\n",
    "    # Wave 2\n",
    "    \"HOME_DIAGNOSTICS\": \"HOME DIAGNOSTICS\",\n",
    "    \"BABY_CARE\": \"BABY CARE\",\n",
    "    \"ALLERGY_REMEDIES\": \"ALLERGY REMEDIES\",\n",
    "    \"HAND_&_BODY\": \"HAND & BODY\",\n",
    "    \"SNACKS\": \"SNACKS\",\n",
    "    \"STATIONERY\": \"STATIONERY\",\n",
    "    \"SHAVING_NEEDS\": \"SHAVING NEEDS\",\n",
    "    \"FACIAL_CARE\": \"FACIAL CARE\",\n",
    "    \"CHILDRENS_REMEDIES\": \"CHILDRENS REMEDIES\",\n",
    "    \"ADULT_CARE\": \"ADULT CARE\",\n",
    "    \"DIET_NUTRITION\": \"DIET/NUTRITION\",\n",
    "    \"ACNE_HSC\": \"ACNE/HSC\",\n",
    "    \"GROCERY\": \"GROCERY\",\n",
    "    \"COLD_REMEDIES\": \"COLD REMEDIES\",\n",
    "    \"DIGESTIVE_HEALTH\": \"DIGESTIVE HEALTH\",\n",
    "    \"HAIR_CARE\": \"HAIR CARE\",\n",
    "    \"EXTERNAL_PAIN\": \"EXTERNAL PAIN\",\n",
    "    \"FIRST_AID\": \"FIRST AID\",\n",
    "    \"CANDY\": \"CANDY\",\n",
    "    \"DEODORANTS\": \"DEODORANTS\",\n",
    "    \"TRIAL_TRAVEL\": \"TRIAL TRAVEL\",\n",
    "    \"FEMININE_CARE\": \"FEMININE CARE\",\n",
    "    \"HAIR_COLOR\": \"HAIR COLOR\",\n",
    "    \"HOUSEHOLD_PAPER\": \"HOUSEHOLD PAPER\",\n",
    "    \"TEXTURED_HAIR\": \"TEXTURED HAIR\",\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) Apply the dictionary to create the CAT_DSC column\n",
    "# ----------------------------------------------------------------------------\n",
    "# If a given 'category' value is not in the dictionary, we can either default\n",
    "# to the original string or set it to something like 'UNKNOWN'\n",
    "df_filtered[\"CAT_DSC\"] = df_filtered[\"category\"].map(category_mapping).fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5282928-bc1c-4ac9-903e-f01070ca9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_categories = df_filtered.loc[df_filtered[\"CAT_DSC\"].isna(), \"category\"].unique()\n",
    "assert len(missing_categories) == 0, f\"Missing CAT_DSC mapping for categories: {missing_categories}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d48428-ec95-4c6a-867b-6bc42c4d78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the official CAT_DSC strings too, so we compare on the same basis.\n",
    "# # We'll keep an extra structure mapping normalized -> original official.\n",
    "# normalized_to_original = {}\n",
    "# for cat in official_categories:\n",
    "#     norm = normalize_str(cat)\n",
    "#     normalized_to_original[norm] = cat  # store the *exact* original\n",
    "\n",
    "# normalized_official = list(normalized_to_original.keys())\n",
    "\n",
    "# df_filtered[\"CAT_DSC\"] = df_filtered[\"category\"].apply(map_category_to_cat_dsc)\n",
    "\n",
    "# ###############################################################################\n",
    "# # End result\n",
    "# ###############################################################################\n",
    "# print(df_filtered.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94ab1380-71d4-4837-9cf5-c0697e57fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CANDY    6827\n",
       "Name: CAT_DSC, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[\"CAT_DSC\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eabb5dec-459d-4dbe-8ef7-72a50d8bb0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CANDY    6827\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d1581fd-b655-4975-8f07-a50217975049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CANDY'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[\"CAT_DSC\"].unique()\n",
    "# array(['BEVERAGES', 'VITAMINS', 'PERSONAL_CLEANSING', 'HOUSEHOLD',\n",
    "#        'ORAL_HYGIENE'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7c296f2-e178-438d-a405-1c69abfbc1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6827, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape\n",
    "# (34145, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19a91c9c-eeb0-4c28-b684-8ff22110a060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>category</th>\n",
       "      <th>external_cluster_labels</th>\n",
       "      <th>internal_cluster_labels</th>\n",
       "      <th>demand_cluster_labels</th>\n",
       "      <th>rebalanced_demand_cluster_labels</th>\n",
       "      <th>CAT_DSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5231</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5_2</td>\n",
       "      <td>5_2</td>\n",
       "      <td>CANDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1435</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6_1</td>\n",
       "      <td>6_1</td>\n",
       "      <td>CANDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9647</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3_1</td>\n",
       "      <td>3_1</td>\n",
       "      <td>CANDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8945</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6_1</td>\n",
       "      <td>6_1</td>\n",
       "      <td>CANDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5045</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>CANDY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr category  external_cluster_labels  internal_cluster_labels  \\\n",
       "0       5231    CANDY                        5                        2   \n",
       "1       1435    CANDY                        6                        1   \n",
       "2       9647    CANDY                        3                        1   \n",
       "3       8945    CANDY                        6                        1   \n",
       "4       5045    CANDY                        1                        1   \n",
       "\n",
       "  demand_cluster_labels rebalanced_demand_cluster_labels CAT_DSC  \n",
       "0                   5_2                              5_2   CANDY  \n",
       "1                   6_1                              6_1   CANDY  \n",
       "2                   3_1                              3_1   CANDY  \n",
       "3                   6_1                              6_1   CANDY  \n",
       "4                   1_1                              1_1   CANDY  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b54024f7-6196-4fd8-9471-972cfee67eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CANDY'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.CAT_DSC.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe5b86-1f10-4f5e-800a-72aec731233d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6619ff51-c238-438b-896f-2847df6ac28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_datetime = earliest_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e06504ad-4723-40b9-a53d-fec33879de3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside config.py slfsvc-twa07\n",
      "Inside config.py slfsvc-twa07\n",
      "printing snowflake connection dic {'SF_USER_NAME': 'sa_slfsvc_fsca_app_twa_07', 'SF_ACCOUNT': 'cvsfrontstore.east-us-2.privatelink', 'SF_WAREHOUSE': 'WH_FSCA_TWA_07', 'SF_USER_ROLE': 'ROLE_FSCA_TWA07_BATCH_FR', 'SF_DB': 'CORE_FS', 'SF_AUDIT_SCHEMA': 'WORK_FS'}\n",
      "printing sfparms {'SF_USER_NAME': 'sa_slfsvc_fsca_app_twa_07', 'SF_ACCOUNT': 'cvsfrontstore.east-us-2.privatelink', 'SF_WAREHOUSE': 'WH_FSCA_TWA_07', 'SF_USER_ROLE': 'ROLE_FSCA_TWA07_BATCH_FR', 'SF_DB': 'CORE_FS', 'SF_AUDIT_SCHEMA': 'WORK_FS'}\n",
      "2025-04-14 16:44:00,316 - fsutils.run_sf_sql - INFO - Establishing Snowflake Connection\n",
      "Getting snowflake key file from Azure Key Vault\n",
      "Getting snowflake key pass from Azure Key Vault\n",
      "2025-04-14 16:44:27,982 - fsutils.run_sf_sql - INFO -  Getting Snowflake Cursor\n",
      "2025-04-14 16:44:27,983 - fsutils.run_sf_sql - INFO - Got the cursor\n",
      "Data written to table: FINAL_ASSORTMENT_STORE_CLUSTERS\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Snowflake-related imports and writing to Snowflake\n",
    "# -------------------------------------------------------------------\n",
    "from fsutils import run_sf_sql as rp, config, email, adls_gen2\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "# Define the config map name\n",
    "configmapname = \"notebook-medium\"\n",
    "\n",
    "# Get configs\n",
    "params = config.get_config(configmapname)\n",
    "\n",
    "# Get the SF connection\n",
    "conn, cur = rp.get_connection(configmapname)\n",
    "\n",
    "df = df_filtered.copy()\n",
    "\n",
    "# 7) Form our table name using the latest date/time\n",
    "#    (if you only want the date, you could parse out the YYYYMMDD)\n",
    "# table_name = f\"ASSORTMENT_STORE_CLUSTERS_{latest_datetime}\"\n",
    "table_name = \"FINAL_ASSORTMENT_STORE_CLUSTERS\"\n",
    "\n",
    "# 8) Write to Snowflake\n",
    "write_pandas(\n",
    "    conn,\n",
    "    df,\n",
    "    table_name,\n",
    "    database=\"DL_FSCA_SLFSRV\",\n",
    "    schema=\"TWA07\",\n",
    "    overwrite=True,\n",
    "    auto_create_table=True,\n",
    ")\n",
    "\n",
    "print(f\"Data written to table: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829d41e-2ad2-4023-a6f5-24cdbb2085be",
   "metadata": {},
   "source": [
    "### Appending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e10d3ea3-9fd7-4f56-8aa0-1dffd5802be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_name = \"FINAL_ASSORTMENT_STORE_CLUSTERS_ARCHIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a6b8551-a121-400f-ba2b-c37381850a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive = df.copy()\n",
    "# add a column called timestamp and use this variable latest_datetime\n",
    "df_archive[\"timestamp\"] = latest_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbaf6819-ae6a-40eb-a949-c97cdb24df16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 1,\n",
       " 6827,\n",
       " [('gqwonolcdt/file0.txt',\n",
       "   'LOADED',\n",
       "   6827,\n",
       "   6827,\n",
       "   1,\n",
       "   0,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_pandas(\n",
    "    conn,\n",
    "    df_archive,\n",
    "    master_name,\n",
    "    database=\"DL_FSCA_SLFSRV\",\n",
    "    schema=\"TWA07\",\n",
    "    overwrite=False,\n",
    "    auto_create_table=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700b43e-91c4-4c09-909d-4a3ac649490f",
   "metadata": {},
   "source": [
    "## Adhoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d141a8f1-c290-48e6-a0f5-c5d6c51c27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dighealth = pd.read_sql(\n",
    "    \"select * from DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250321_1842_DIGHEALTH\", conn\n",
    ")\n",
    "snacks = pd.read_sql(\n",
    "    \"select * from DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250401_1553_SNACKS\", conn\n",
    ")\n",
    "candy = pd.read_sql(\n",
    "    \"select * from DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250402_1949_CANDY\", conn\n",
    ")\n",
    "final_assortment = pd.read_sql(\n",
    "    \"select * from DL_FSCA_SLFSRV.TWA07.FINAL_ASSORTMENT_STORE_CLUSTERS\", conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c751f27-ed8b-4756-805f-15265fd6f73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>category</th>\n",
       "      <th>external_cluster_labels</th>\n",
       "      <th>internal_cluster_labels</th>\n",
       "      <th>demand_cluster_labels</th>\n",
       "      <th>rebalanced_demand_cluster_labels</th>\n",
       "      <th>CAT_DSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5231</td>\n",
       "      <td>DIGESTIVE_HEALTH</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7_1</td>\n",
       "      <td>7_1</td>\n",
       "      <td>DIGESTIVE HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1435</td>\n",
       "      <td>DIGESTIVE_HEALTH</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>DIGESTIVE HEALTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr          category  external_cluster_labels  \\\n",
       "0       5231  DIGESTIVE_HEALTH                        7   \n",
       "1       1435  DIGESTIVE_HEALTH                        1   \n",
       "\n",
       "   internal_cluster_labels demand_cluster_labels  \\\n",
       "0                        1                   7_1   \n",
       "1                        3                   1_3   \n",
       "\n",
       "  rebalanced_demand_cluster_labels           CAT_DSC  \n",
       "0                              7_1  DIGESTIVE HEALTH  \n",
       "1                              1_3  DIGESTIVE HEALTH  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dighealth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d22f515-daa9-4907-bb28-c4deeb4a7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "snacks = snacks.rename(\n",
    "    columns={\"STORE_NBR\": \"store_nbr\", \"CLUSTER\": \"rebalanced_demand_cluster_labels\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2757561b-53f4-4a9e-9814-94649af14b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>category</th>\n",
       "      <th>external_cluster_labels</th>\n",
       "      <th>internal_cluster_labels</th>\n",
       "      <th>demand_cluster_labels</th>\n",
       "      <th>rebalanced_demand_cluster_labels</th>\n",
       "      <th>CAT_DSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5231</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6_0</td>\n",
       "      <td>6_0</td>\n",
       "      <td>CANDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1435</td>\n",
       "      <td>CANDY</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3_2</td>\n",
       "      <td>3_2</td>\n",
       "      <td>CANDY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr category  external_cluster_labels  internal_cluster_labels  \\\n",
       "0       5231    CANDY                        6                        0   \n",
       "1       1435    CANDY                        3                        2   \n",
       "\n",
       "  demand_cluster_labels rebalanced_demand_cluster_labels CAT_DSC  \n",
       "0                   6_0                              6_0   CANDY  \n",
       "1                   3_2                              3_2   CANDY  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83608ca2-913a-4898-9310-8dd03662f765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>category</th>\n",
       "      <th>external_cluster_labels</th>\n",
       "      <th>internal_cluster_labels</th>\n",
       "      <th>demand_cluster_labels</th>\n",
       "      <th>rebalanced_demand_cluster_labels</th>\n",
       "      <th>CAT_DSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5231</td>\n",
       "      <td>HAIR_CARE</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2_1</td>\n",
       "      <td>2_1</td>\n",
       "      <td>HAIR CARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1435</td>\n",
       "      <td>HAIR_CARE</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3_0</td>\n",
       "      <td>3_0</td>\n",
       "      <td>HAIR CARE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr   category  external_cluster_labels  internal_cluster_labels  \\\n",
       "0       5231  HAIR_CARE                        2                        1   \n",
       "1       1435  HAIR_CARE                        3                        0   \n",
       "\n",
       "  demand_cluster_labels rebalanced_demand_cluster_labels    CAT_DSC  \n",
       "0                   2_1                              2_1  HAIR CARE  \n",
       "1                   3_0                              3_0  HAIR CARE  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_assortment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07a6dda6-dd76-44c7-9ca3-96c8d4c34e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrames\n",
    "merged_df = pd.concat([dighealth, snacks, candy, final_assortment], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bcff1594-1cf6-48ba-baad-821aeb73b96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>category</th>\n",
       "      <th>external_cluster_labels</th>\n",
       "      <th>internal_cluster_labels</th>\n",
       "      <th>demand_cluster_labels</th>\n",
       "      <th>rebalanced_demand_cluster_labels</th>\n",
       "      <th>CAT_DSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5231</td>\n",
       "      <td>DIGESTIVE_HEALTH</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7_1</td>\n",
       "      <td>7_1</td>\n",
       "      <td>DIGESTIVE HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1435</td>\n",
       "      <td>DIGESTIVE_HEALTH</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>DIGESTIVE HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9647</td>\n",
       "      <td>DIGESTIVE_HEALTH</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4_3</td>\n",
       "      <td>4_3</td>\n",
       "      <td>DIGESTIVE HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8945</td>\n",
       "      <td>DIGESTIVE_HEALTH</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>1_3</td>\n",
       "      <td>DIGESTIVE HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5045</td>\n",
       "      <td>DIGESTIVE_HEALTH</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5_3</td>\n",
       "      <td>5_3</td>\n",
       "      <td>DIGESTIVE HEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27301</th>\n",
       "      <td>2145</td>\n",
       "      <td>HAIR_CARE</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6_0</td>\n",
       "      <td>6_0</td>\n",
       "      <td>HAIR CARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27302</th>\n",
       "      <td>9188</td>\n",
       "      <td>HAIR_CARE</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8_2</td>\n",
       "      <td>8_2</td>\n",
       "      <td>HAIR CARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27303</th>\n",
       "      <td>11245</td>\n",
       "      <td>HAIR_CARE</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3_0</td>\n",
       "      <td>3_0</td>\n",
       "      <td>HAIR CARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27304</th>\n",
       "      <td>10892</td>\n",
       "      <td>HAIR_CARE</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3_0</td>\n",
       "      <td>3_0</td>\n",
       "      <td>HAIR CARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27305</th>\n",
       "      <td>6133</td>\n",
       "      <td>HAIR_CARE</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7_1</td>\n",
       "      <td>7_1</td>\n",
       "      <td>HAIR CARE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27306 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store_nbr          category  external_cluster_labels  \\\n",
       "0           5231  DIGESTIVE_HEALTH                        7   \n",
       "1           1435  DIGESTIVE_HEALTH                        1   \n",
       "2           9647  DIGESTIVE_HEALTH                        4   \n",
       "3           8945  DIGESTIVE_HEALTH                        1   \n",
       "4           5045  DIGESTIVE_HEALTH                        5   \n",
       "...          ...               ...                      ...   \n",
       "27301       2145         HAIR_CARE                        6   \n",
       "27302       9188         HAIR_CARE                        8   \n",
       "27303      11245         HAIR_CARE                        3   \n",
       "27304      10892         HAIR_CARE                        3   \n",
       "27305       6133         HAIR_CARE                        7   \n",
       "\n",
       "       internal_cluster_labels demand_cluster_labels  \\\n",
       "0                            1                   7_1   \n",
       "1                            3                   1_3   \n",
       "2                            3                   4_3   \n",
       "3                            3                   1_3   \n",
       "4                            3                   5_3   \n",
       "...                        ...                   ...   \n",
       "27301                        0                   6_0   \n",
       "27302                        2                   8_2   \n",
       "27303                        0                   3_0   \n",
       "27304                        0                   3_0   \n",
       "27305                        1                   7_1   \n",
       "\n",
       "      rebalanced_demand_cluster_labels           CAT_DSC  \n",
       "0                                  7_1  DIGESTIVE HEALTH  \n",
       "1                                  1_3  DIGESTIVE HEALTH  \n",
       "2                                  4_3  DIGESTIVE HEALTH  \n",
       "3                                  1_3  DIGESTIVE HEALTH  \n",
       "4                                  5_3  DIGESTIVE HEALTH  \n",
       "...                                ...               ...  \n",
       "27301                              6_0         HAIR CARE  \n",
       "27302                              8_2         HAIR CARE  \n",
       "27303                              3_0         HAIR CARE  \n",
       "27304                              3_0         HAIR CARE  \n",
       "27305                              7_1         HAIR CARE  \n",
       "\n",
       "[27306 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de58f2f7-4535-41af-a5b8-ee5c2857e0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 1,\n",
       " 27306,\n",
       " [('hvyryxemgd/file0.txt',\n",
       "   'LOADED',\n",
       "   27306,\n",
       "   27306,\n",
       "   1,\n",
       "   0,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_pandas(\n",
    "    conn,\n",
    "    merged_df,\n",
    "    f\"FINAL_ASSORTMENT_STORE_CLUSTERS_{latest_datetime}_MERGED\",\n",
    "    database=\"DL_FSCA_SLFSRV\",\n",
    "    schema=\"TWA07\",\n",
    "    overwrite=True,\n",
    "    auto_create_table=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7cb3180-f6c1-47d5-abdc-ad1029998f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINAL_ASSORTMENT_STORE_CLUSTERS_20250409_1606_MERGED'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"FINAL_ASSORTMENT_STORE_CLUSTERS_{latest_datetime}_MERGED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d536731-1bfa-4fe8-8ac5-06d4eeef25fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from fsutils import run_sf_sql as rp, config, email, adls_gen2, log\n",
    "\n",
    "conn, cur = rp.get_connection(\"notebook-medium\")\n",
    "import pandas as pd\n",
    "\n",
    "# Define the table names\n",
    "tables = [\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250312_1859\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250313_1956\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250319_1339\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250319_1934\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250320_1843\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250321_1446\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250321_1842\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250324_2027\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250325_1347\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250325_1719\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250326_1342\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250326_1529\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250326_1717\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250326_1901\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250327_1912\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250328_1901\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250331_1351\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250331_1701\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250401_1553\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250402_1949\",\n",
    "    \"DL_FSCA_SLFSRV.TWA07.ASSORTMENT_STORE_CLUSTERS_20250403_1746\",\n",
    "]\n",
    "\n",
    "# Additional table with its own timestamp\n",
    "table2 = [\"DL_FSCA_SLFSRV.TWA07.FINAL_ASSORTMENT_STORE_CLUSTERS_ARCHIVE\"]\n",
    "\n",
    "\n",
    "# Define a function to preprocess timestamps\n",
    "def preprocess_timestamp(timestamp):\n",
    "    try:\n",
    "        # If the timestamp is already in a valid format, return it\n",
    "        return pd.to_datetime(timestamp)\n",
    "    except:\n",
    "        # Handle custom format like '20250404_1615'\n",
    "        if \"_\" in timestamp:\n",
    "            date_part, time_part = timestamp.split(\"_\")\n",
    "            formatted_timestamp = f\"{date_part[:4]}-{date_part[4:6]}-{date_part[6:]} {time_part[:2]}:{time_part[2:]}:00\"\n",
    "            return pd.to_datetime(formatted_timestamp)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown timestamp format: {timestamp}\")\n",
    "\n",
    "\n",
    "# Load data from each table, add timestamp column, and concatenate\n",
    "dataframes = []\n",
    "\n",
    "# Process tables with timestamps\n",
    "for table in tables:\n",
    "    # Extract the date from the table name\n",
    "    date_str = table.split(\"_\")[-2]  # Extract '20250312' part\n",
    "    timestamp = pd.to_datetime(date_str, format=\"%Y%m%d\")  # Convert to datetime\n",
    "\n",
    "    # Query the table\n",
    "    query = f\"SELECT * FROM {table}\"\n",
    "    df = pd.read_sql(query, conn)  # Replace 'conn' with your database connection object\n",
    "\n",
    "    # Add the timestamp column\n",
    "    df[\"timestamp\"] = timestamp\n",
    "\n",
    "    # Append to the list of DataFrames\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames from the first set of tables\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Process the additional table (table2) with its own timestamp\n",
    "for table in table2:\n",
    "    query = f\"SELECT * FROM {table}\"\n",
    "    df_table2 = pd.read_sql(query, conn)  # Replace 'conn' with your database connection object\n",
    "\n",
    "    # Ensure the timestamp column exists in table2\n",
    "    if \"timestamp\" not in df_table2.columns:\n",
    "        raise ValueError(f\"The table {table} does not have a 'timestamp' column.\")\n",
    "\n",
    "    # Append table2 to the final DataFrame\n",
    "    final_df = pd.concat([final_df, df_table2], ignore_index=True)\n",
    "\n",
    "# Enforce consistent timestamp format\n",
    "final_df[\"timestamp\"] = final_df[\"timestamp\"].apply(preprocess_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efed0e2a-9c9d-400c-9123-d769edc033fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 1,\n",
       " 566401,\n",
       " [('urrclvppuv/file0.txt',\n",
       "   'LOADED',\n",
       "   566401,\n",
       "   566401,\n",
       "   1,\n",
       "   0,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_pandas(\n",
    "    conn,\n",
    "    final_df,\n",
    "    f\"FINAL_ASSORTMENT_STORE_CLUSTERS_MERGED_MICHELLE_Apr_10_2025\",\n",
    "    database=\"DL_FSCA_SLFSRV\",\n",
    "    schema=\"TWA07\",\n",
    "    overwrite=True,\n",
    "    auto_create_table=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef365ef3-08b8-4dae-9fa4-b055972d8066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
