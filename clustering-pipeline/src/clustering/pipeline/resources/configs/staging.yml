alerts:
  enabled: true
  threshold: WARNING
azure_storage:
  account_key: ${AZURE_STORAGE_KEY}
  account_name: ${AZURE_STORAGE_ACCOUNT}
io_manager: {}
logger:
  level: INFO
  sink: logs/dagster_staging.log
# Job configuration parameters
job_params:
  # Common parameters
  algorithm: "kmeans"
  normalize: true
  norm_method: "robust"
  pca_active: true
  pca_components: 0.8
  ignore_features: ["STORE_NBR"]

  # KMeans parameters
  kmeans:
    n_clusters: 5
    random_state: 42
    n_init: 10
    max_iter: 300

  # Preprocessing parameters
  preprocessing:
    feature_selection:
      min_variance: 0.01
      max_correlation: 0.95
    outlier_detection:
      method: "IQR"
      threshold: 1.5

  # Evaluation parameters
  evaluation:
    metrics:
      - "silhouette_score"
      - "davies_bouldin_score"
# Data sources and destinations
readers:
  external_sales:
    kind: "SnowflakeReader"
    config:
      query: SELECT * FROM STAGING_CLUSTERING_DB.RAW.EXTERNAL_SALES
  need_state:
    kind: "BlobReader"
    config:
      blob_name: internal/need_state.csv
  sales:
    kind: "BlobReader"
    config:
      blob_name: internal/sales.parquet
writers:
  external_data_output:
    kind: "SnowflakeWriter"
    config:
      table: STAGING_CLUSTERING_DB.PROCESSED.EXTERNAL_DATA
      database: STAGING_CLUSTERING_DB
      schema: PROCESSED
  internal_clusters_output:
    kind: "SnowflakeWriter"
    config:
      table: STAGING_CLUSTERING_DB.PROCESSED.INTERNAL_CLUSTERS
      database: STAGING_CLUSTERING_DB
      schema: PROCESSED
  sales_by_category:
    kind: "BlobWriter"
    config:
      blob_name: internal/sales_processed.parquet
  sales_percent:
    kind: "BlobWriter"
    config:
      blob_name: internal/sales_percent.parquet
  merged_clusters_output:
    kind: "SnowflakeWriter"
    config:
      table: STAGING_CLUSTERING_DB.PROCESSED.MERGED_CLUSTERS
      database: STAGING_CLUSTERING_DB
      schema: PROCESSED
